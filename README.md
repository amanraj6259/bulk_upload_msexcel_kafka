 Kafka producer settings
spring.kafka.bootstrap-servers=localhost:9092
â¡ The Kafka server (broker) is running locally on port 9092.
ğŸ’¡ Like saying: â€œKafka, my app will connect to you at this address.â€
spring.kafka.topic.driver-location=student-topic
â¡ The Kafka topic name your app uses to send/read messages â†’ student-topic.
ğŸ’¡ Example: All student data will be published/consumed from student-topic.

spring.kafka.producer.retries=2
â¡ Kafka producer will retry 2 times if sending a message fails (due to network issue, etc).

ğŸ’¡ Example: You try to send a student message â†’ network glitch â†’ Kafka tries 2 more times before giving up.

spring.kafka.producer.acks=1
â¡ Kafka broker will reply â€œOKâ€ after leader node gets the message.

ğŸ’¡ Example:

acks=0 â†’ no reply needed

acks=1 â†’ leader got it, reply OK (your case)

acks=all â†’ leader + followers got it before reply

ğŸŸ¢ Kafka consumer settings

spring.kafka.consumer.group-id=student-group
â¡ All consumers with this ID will balance reading of messages.
ğŸ’¡ Example: You have 4 app instances â†’ Kafka divides messages among them (load sharing).

spring.kafka.consumer.auto-offset-reset=earliest
â¡ When no offset is found â†’ Kafka reads messages from the beginning of the topic.

ğŸ’¡ Example: First time you start your app â†’ it reads all old messages in student-topic.

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
â¡ Kafka converts message key (if any) to String so your app can understand it.


spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
â¡ Kafka converts message value (the student data) from JSON to your Java Student object.

spring.kafka.consumer.properties.spring.json.value.default.type=com.bulkupload.model.Student
â¡ Tells Kafka what class the JSON represents â†’ Student.

ğŸ’¡ Example: Kafka sees JSON â†’ converts into Student:
{"std_id":1, "name":"Aman", "email":"a@a.com", "location":"Delhi"}
â¡ â†’ Student object.

spring.kafka.consumer.properties.reconnect.backoff.ms=5000
spring.kafka.producer.properties.reconnect.backoff.ms=5000
â¡ If Kafka connection fails â†’ wait 5000 ms = 5 seconds before retrying to reconnect.

ğŸ’¡ Example: Kafka goes down â†’ app waits 5 seconds â†’ tries again.



| **Parameter**                | **Laymanâ€™s Meaning**                                                                                                                                                       | **Example**                                                                                 | **Where You Set This?**                                                       |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **Topic Name**               | The unique name for a queue where messages (data) go. Think of it like a folder name where youâ€™re dropping your student messages.                                          | `student-topic`                                                                             | You define this when you create the topic (via Kafka UI or terminal command)  |
| **Partitions**               | Think of a topic as a big box divided into sections (partitions). Each section holds part of your data. More partitions = can process faster, in parallel.                 | 4 partitions â†’ 1 for each school/location (e.g., `delhi`, `mumbai`, `bangalore`, `chennai`) | When creating the topic (UI or terminal); **canâ€™t change easily later**       |
| **Cleanup Policy**           | What to do with old data in the topic? <br> `delete`: throw away data after some time or size <br> `compact`: keep only latest data per key                                | For student records, usually `delete` (after 7 days).                                       | When creating topic (UI or terminal). Can update later with Kafka commands.   |
| **Min In Sync Replicas**     | How many copies (replicas) of your data must confirm they saved it before Kafka says â€œdone.â€ <br> Think of sending a parcel â€” how many receivers must confirm they got it? | 1 for dev (1 broker) <br> 2+ for production (multiple brokers)                              | Kafka topic config (UI or terminal); not in application.properties            |
| **Replication Factor**       | How many *copies* of your data Kafka should keep. This helps in case a broker (server) fails â€” other copies will serve the data.                                           | 1 for dev (no copy) <br> 2-3 for production                                                 | When creating the topic (UI or terminal); canâ€™t change after topic is created |
| **Retention Time (ms)**      | How long Kafka keeps the data in the topic before deleting it. <br> Like saying: â€œClear this folder every 7 days.â€                                                         | `604800000` (7 days) <br> `86400000` (1 day)                                                | Set at topic creation (UI or terminal) or can change later via Kafka config   |
| **Max size on disk (GB)**    | How big (in GB) the topic can grow before Kafka starts deleting old messages (if using `delete` policy).                                                                   | e.g. `10 GB` â†’ keep max 10 GB data at a time                                                | Topic config (UI or terminal)                                                 |
| **Max message size (bytes)** | The biggest single message Kafka will accept. Useful for large data uploads.                                                                                               | Default = 1MB (1048576 bytes)                                                               | Broker level setting; not usually set per topic or in application.properties  |
| **Custom parameters**        | Extra configs like compression type, specific retention bytes, etc. Advanced tuning.                                                                                       | 
Example: `compression.type=gzip`                                                            | Kafka topic config (UI or terminal)                                           |




Compose.yml file for docker

âœ… Sure! Letâ€™s break down your **Docker Compose file** (for Zookeeper + Kafka + Kafka-UI) in **simple, laymanâ€™s terms**.

---

# ğŸŒŸ **VERSION**

```yaml
version: '3.1'
```

â¡ This tells Docker we are using **Compose syntax version 3.1**, which is compatible with modern Docker.

---

# ğŸŒŸ **SERVICES**

Your app has **3 services (or mini-apps)** that Docker will run:
1ï¸âƒ£ Zookeeper
2ï¸âƒ£ Kafka
3ï¸âƒ£ Kafka-UI

Each service runs in its **own container (mini computer)**.

---

## ğŸš€ **1ï¸âƒ£ Zookeeper**

```yaml
services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
```

â–¶ **image:**
Weâ€™re using the prebuilt image `wurstmeister/zookeeper`.
ğŸ‘‰ Think of this like a ready-made app to run Zookeeper.

â–¶ **container\_name:**
Weâ€™re naming the container **`zookeeper`** so it's easy to refer to.

â–¶ **ports:**
We are saying:

* **"2181:2181"** â†’ Expose port 2181 on your PC, and connect it to port 2181 inside the container.
* Zookeeper uses **2181** by default so Kafka can talk to it.

ğŸ’¡ *Zookeeper keeps track of Kafka clusterâ€™s metadata (brokers, topics, configs).*

---

## ğŸš€ **2ï¸âƒ£ Kafka**

```yaml
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
```

â–¶ **image:**
Uses `wurstmeister/kafka` â†’ a ready-made Kafka image.

â–¶ **container\_name:**
Names the container **`kafka`**.

â–¶ **ports:**

* **"9092:9092"** â†’ Connect port 9092 of your PC to port 9092 inside the container.
* This lets you connect to Kafka on `localhost:9092` from your apps.

â–¶ **environment:**
Weâ€™re setting config values that Kafka needs:

* `KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092`
  â†’ Kafka listens on all network interfaces on port 9092 (inside container).

* `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092`
  â†’ Tells clients (your apps) to connect to Kafka using `localhost:9092`.

* `KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181`
  â†’ Tells Kafka where to find Zookeeper (our service `zookeeper` on port 2181).

ğŸ’¡ *Kafka brokers messages; apps can publish (send) and subscribe (read) data.*

---

## ğŸš€ **3ï¸âƒ£ Kafka-UI**

```yaml
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8089:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: localhost:9092
    depends_on:
      - kafka
```

â–¶ **image:**
Uses `provectuslabs/kafka-ui` â†’ this is a nice web app to view Kafka topics, messages, and more.

â–¶ **container\_name:**
We call this container **`kafka-ui`**.

â–¶ **ports:**

* **"8089:8080"** â†’ Inside the container, Kafka-UI runs on port 8080. On your PC, youâ€™ll open browser at `localhost:8089`.

â–¶ **environment:**
Settings for the Kafka-UI tool:

* `KAFKA_CLUSTERS_0_NAME: local-kafka`
  â†’ We give this cluster a name ("local-kafka") in the UI.

* `KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: localhost:9092`
  â†’ We tell Kafka-UI how to connect to Kafka (at `localhost:9092`).

â–¶ **depends\_on:**
Kafka-UI will wait for Kafka to start first.

ğŸ’¡ *Kafka-UI is like a dashboard where you can see what's going on inside Kafka.*

---

# âœ… **Summary of what happens**

ğŸ‘‰ When you run `docker-compose up`:

* A **Zookeeper server** starts (port 2181).
* A **Kafka server** starts, talks to Zookeeper (port 9092 for client apps).
* A **Kafka-UI web app** starts (open `http://localhost:8089`).

---

ğŸ’¡ **Bonus Tip:** If you'd like, I can draw a simple diagram for this setup or help you add persistence (data saved on disk)!

Do you want that? ğŸš€
