Kafka Producer config code

| Part                                           | What is it? (Layman‚Äôs meaning)                                                                             | Example / Why we need it                                                                              |
| ---------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
| `@Configuration`                               | This tells Spring Boot: ‚ÄúHey! This is a **Java class that defines beans (objects Spring should manage)**.‚Äù | Like a blueprint where we define factory machines that produce objects (beans).                       |
| `@Bean`                                        | Marks a method where Spring should **create an object (bean)** and keep it ready to use.                   | Spring auto-creates these objects and injects wherever needed.                                        |
| `@Value("${spring.kafka.bootstrap-servers}")`  | Reads value from `application.properties`.                                                                 | If your `properties` file says: `spring.kafka.bootstrap-servers=localhost:9092`, it fills this value. |
| `ProducerFactory<String, Student>`             | A factory (like a machine) that builds **Kafka Producers** (the part that sends messages).                 | We set properties like server address, serializers etc here.                                          |
| `ProducerConfig.BOOTSTRAP_SERVERS_CONFIG`      | Kafka‚Äôs config key ‚Üí tells Kafka producer where to connect.                                                | e.g. `"localhost:9092"` means connect to Kafka server at this address.                                |
| `ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG`   | Tells Kafka how to convert the **key** into bytes for sending.                                             | We use `StringSerializer` ‚Üí keys like `"student_id"` become bytes.                                    |
| `ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG` | Tells Kafka how to convert the **value (object)** into bytes.                                              | We use `JsonSerializer` ‚Üí `Student` object becomes JSON, then bytes.                                  |
| `DefaultKafkaProducerFactory`                  | Kafka producer factory that uses the config map to make producer instances.                                | Spring Boot calls this factory whenever it needs a producer.                                          |
| `KafkaTemplate<String, Student>`               | Spring‚Äôs helper to **send messages easily to Kafka**.                                                      | Think of it like `JdbcTemplate` for DB ‚Äî it simplifies Kafka code. We use it to call `send()`.        |


COMMON KAFKA TERMS IN SPRING BOOT

| Term                | What is it?                                                          | Example                                                                   |
| ------------------- | -------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **Producer**        | Sends messages to Kafka topic.                                       | Your app generates data (e.g. student info) and sends it.                 |
| **Consumer**        | Listens to a Kafka topic and processes messages.                     | Your app listens for new students to save into DB.                        |
| **Topic**           | A named channel where messages are stored.                           | Like a WhatsApp group where messages arrive ‚Äî e.g. `student-topic`.       |
| **Partition**       | A sub-division of a topic for parallelism.                           | Topic split into parts so multiple consumers can read faster.             |
| **Offset**          | A unique ID for each message in a partition.                         | Keeps track of message position in partition.                             |
| **KafkaTemplate**   | A helper class to send data to Kafka easily.                         | Instead of writing complex Kafka code, you call `kafkaTemplate.send()`.   |
| **ProducerFactory** | Makes producers for sending messages.                                | Like a machine that creates producers on demand.                          |
| **ConsumerFactory** | Makes consumers for receiving messages.                              | Like a machine that creates consumers on demand.                          |
| **Serializer**      | Converts object into bytes (for sending).                            | Converts `Student` to JSON, then to bytes.                                |
| **Deserializer**    | Converts bytes back into object.                                     | Converts JSON bytes to `Student` object.                                  |
| **@KafkaListener**  | Spring annotation to create a method that listens to Kafka messages. | `@KafkaListener(topics="student-topic")` automatically consumes messages. |

 
 Kafka producer settings
spring.kafka.bootstrap-servers=localhost:9092
‚û° The Kafka server (broker) is running locally on port 9092.
üí° Like saying: ‚ÄúKafka, my app will connect to you at this address.‚Äù
spring.kafka.topic.driver-location=student-topic
‚û° The Kafka topic name your app uses to send/read messages ‚Üí student-topic.
üí° Example: All student data will be published/consumed from student-topic.

spring.kafka.producer.retries=2
‚û° Kafka producer will retry 2 times if sending a message fails (due to network issue, etc).

üí° Example: You try to send a student message ‚Üí network glitch ‚Üí Kafka tries 2 more times before giving up.

spring.kafka.producer.acks=1
‚û° Kafka broker will reply ‚ÄúOK‚Äù after leader node gets the message.

üí° Example:

acks=0 ‚Üí no reply needed

acks=1 ‚Üí leader got it, reply OK (your case)

acks=all ‚Üí leader + followers got it before reply

üü¢ Kafka consumer settings

spring.kafka.consumer.group-id=student-group
‚û° All consumers with this ID will balance reading of messages.
üí° Example: You have 4 app instances ‚Üí Kafka divides messages among them (load sharing).

spring.kafka.consumer.auto-offset-reset=earliest
‚û° When no offset is found ‚Üí Kafka reads messages from the beginning of the topic.

üí° Example: First time you start your app ‚Üí it reads all old messages in student-topic.

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
‚û° Kafka converts message key (if any) to String so your app can understand it.


spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
‚û° Kafka converts message value (the student data) from JSON to your Java Student object.

spring.kafka.consumer.properties.spring.json.value.default.type=com.bulkupload.model.Student
‚û° Tells Kafka what class the JSON represents ‚Üí Student.

üí° Example: Kafka sees JSON ‚Üí converts into Student:
{"std_id":1, "name":"Aman", "email":"a@a.com", "location":"Delhi"}
‚û° ‚Üí Student object.

spring.kafka.consumer.properties.reconnect.backoff.ms=5000
spring.kafka.producer.properties.reconnect.backoff.ms=5000
‚û° If Kafka connection fails ‚Üí wait 5000 ms = 5 seconds before retrying to reconnect.

üí° Example: Kafka goes down ‚Üí app waits 5 seconds ‚Üí tries again.



| **Parameter**                | **Layman‚Äôs Meaning**                                                                                                                                                       | **Example**                                                                                 | **Where You Set This?**                                                       |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **Topic Name**               | The unique name for a queue where messages (data) go. Think of it like a folder name where you‚Äôre dropping your student messages.                                          | `student-topic`                                                                             | You define this when you create the topic (via Kafka UI or terminal command)  |
| **Partitions**               | Think of a topic as a big box divided into sections (partitions). Each section holds part of your data. More partitions = can process faster, in parallel.                 | 4 partitions ‚Üí 1 for each school/location (e.g., `delhi`, `mumbai`, `bangalore`, `chennai`) | When creating the topic (UI or terminal); **can‚Äôt change easily later**       |
| **Cleanup Policy**           | What to do with old data in the topic? <br> `delete`: throw away data after some time or size <br> `compact`: keep only latest data per key                                | For student records, usually `delete` (after 7 days).                                       | When creating topic (UI or terminal). Can update later with Kafka commands.   |
| **Min In Sync Replicas**     | How many copies (replicas) of your data must confirm they saved it before Kafka says ‚Äúdone.‚Äù <br> Think of sending a parcel ‚Äî how many receivers must confirm they got it? | 1 for dev (1 broker) <br> 2+ for production (multiple brokers)                              | Kafka topic config (UI or terminal); not in application.properties            |
| **Replication Factor**       | How many *copies* of your data Kafka should keep. This helps in case a broker (server) fails ‚Äî other copies will serve the data.                                           | 1 for dev (no copy) <br> 2-3 for production                                                 | When creating the topic (UI or terminal); can‚Äôt change after topic is created |
| **Retention Time (ms)**      | How long Kafka keeps the data in the topic before deleting it. <br> Like saying: ‚ÄúClear this folder every 7 days.‚Äù                                                         | `604800000` (7 days) <br> `86400000` (1 day)                                                | Set at topic creation (UI or terminal) or can change later via Kafka config   |
| **Max size on disk (GB)**    | How big (in GB) the topic can grow before Kafka starts deleting old messages (if using `delete` policy).                                                                   | e.g. `10 GB` ‚Üí keep max 10 GB data at a time                                                | Topic config (UI or terminal)                                                 |
| **Max message size (bytes)** | The biggest single message Kafka will accept. Useful for large data uploads.                                                                                               | Default = 1MB (1048576 bytes)                                                               | Broker level setting; not usually set per topic or in application.properties  |
| **Custom parameters**        | Extra configs like compression type, specific retention bytes, etc. Advanced tuning.                                                                                       | 
Example: `compression.type=gzip`                                                            | Kafka topic config (UI or terminal)                                           |




Compose.yml file for docker

‚úÖ Sure! Let‚Äôs break down your **Docker Compose file** (for Zookeeper + Kafka + Kafka-UI) in **simple, layman‚Äôs terms**.

---

# üåü **VERSION**

```yaml
version: '3.1'
```

‚û° This tells Docker we are using **Compose syntax version 3.1**, which is compatible with modern Docker.

---

# üåü **SERVICES**

Your app has **3 services (or mini-apps)** that Docker will run:
1Ô∏è‚É£ Zookeeper
2Ô∏è‚É£ Kafka
3Ô∏è‚É£ Kafka-UI

Each service runs in its **own container (mini computer)**.

---

## üöÄ **1Ô∏è‚É£ Zookeeper**

```yaml
services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
```

‚ñ∂ **image:**
We‚Äôre using the prebuilt image `wurstmeister/zookeeper`.
üëâ Think of this like a ready-made app to run Zookeeper.

‚ñ∂ **container\_name:**
We‚Äôre naming the container **`zookeeper`** so it's easy to refer to.

‚ñ∂ **ports:**
We are saying:

* **"2181:2181"** ‚Üí Expose port 2181 on your PC, and connect it to port 2181 inside the container.
* Zookeeper uses **2181** by default so Kafka can talk to it.

üí° *Zookeeper keeps track of Kafka cluster‚Äôs metadata (brokers, topics, configs).*

---

## üöÄ **2Ô∏è‚É£ Kafka**

```yaml
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
```

‚ñ∂ **image:**
Uses `wurstmeister/kafka` ‚Üí a ready-made Kafka image.

‚ñ∂ **container\_name:**
Names the container **`kafka`**.

‚ñ∂ **ports:**

* **"9092:9092"** ‚Üí Connect port 9092 of your PC to port 9092 inside the container.
* This lets you connect to Kafka on `localhost:9092` from your apps.

‚ñ∂ **environment:**
We‚Äôre setting config values that Kafka needs:

* `KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092`
  ‚Üí Kafka listens on all network interfaces on port 9092 (inside container).

* `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092`
  ‚Üí Tells clients (your apps) to connect to Kafka using `localhost:9092`.

* `KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181`
  ‚Üí Tells Kafka where to find Zookeeper (our service `zookeeper` on port 2181).

üí° *Kafka brokers messages; apps can publish (send) and subscribe (read) data.*

---

## üöÄ **3Ô∏è‚É£ Kafka-UI**

```yaml
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8089:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: localhost:9092
    depends_on:
      - kafka
```

‚ñ∂ **image:**
Uses `provectuslabs/kafka-ui` ‚Üí this is a nice web app to view Kafka topics, messages, and more.

‚ñ∂ **container\_name:**
We call this container **`kafka-ui`**.

‚ñ∂ **ports:**

* **"8089:8080"** ‚Üí Inside the container, Kafka-UI runs on port 8080. On your PC, you‚Äôll open browser at `localhost:8089`.

‚ñ∂ **environment:**
Settings for the Kafka-UI tool:

* `KAFKA_CLUSTERS_0_NAME: local-kafka`
  ‚Üí We give this cluster a name ("local-kafka") in the UI.

* `KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: localhost:9092`
  ‚Üí We tell Kafka-UI how to connect to Kafka (at `localhost:9092`).

‚ñ∂ **depends\_on:**
Kafka-UI will wait for Kafka to start first.

üí° *Kafka-UI is like a dashboard where you can see what's going on inside Kafka.*

---

# ‚úÖ **Summary of what happens**

üëâ When you run `docker-compose up`:

* A **Zookeeper server** starts (port 2181).
* A **Kafka server** starts, talks to Zookeeper (port 9092 for client apps).
* A **Kafka-UI web app** starts (open `http://localhost:8089`).

---

üí° **Bonus Tip:** If you'd like, I can draw a simple diagram for this setup or help you add persistence (data saved on disk)!

Do you want that? üöÄ
